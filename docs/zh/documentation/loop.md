Below is an example of an RL training loop.
```python
import legent

env = legent.Environment(path="<path to excutable file>")

try:
    # RL loop
    for i in range(10000):
        action = {  # This should be generated by your model, here we just keep the AI jump forward
            "move_right": 0,
            "move_forward": 1,
            "look_yaw": 0.0,
            "look_pitch": 0.0,
            "jump": True,
            "grab": False,
            "speak": "",
        }
        observation, reward, done, info = env.step(**action)
        # NOTE: Reward here is for naive "come here". Ignore it.
        vision_obs, language_obs = observation
        game_states = info["game_states"]
        # Use game_states to calculate your own reward and done.
        # reward, done = your_function(game_states)

        # Example: if player grabs something, print the object
        # the game states may help you to calculate your custom reward
        if game_states["playerGrabInstance"] != -1:
            print(game_states["instances"][game_states["playerGrabInstance"]])

        # Example: if player say something, print the text
        if language_obs:
            print("Observation:", language_obs)

        # Example: store the first-person-view image of the playmate (AI agent)
        # !pip install scikit-image
        # import skimage
        # skimage.io.imsave(f"saved_image/playmate_view{i:0>6d}.png", vision_obs, check_contrast=False)

        # Model training here

        if done:
            vision_obs, language_obs = env.reset()
except Exception as e:
    print("Exception:", e)
finally:
    env.close()
```